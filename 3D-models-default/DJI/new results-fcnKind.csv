MAE,Accuracy,F-score
0.4678785739696189,0.6164383561643836,0.3813559322033898
0.4184283724386398,0.6164383561643836,0.3813559322033898
0.4763460885988523,0.6164383561643836,0.3813559322033898
0.4642655167677631,0.6164383561643836,0.3813559322033898
0.46994454730046936,0.6164383561643836,0.3813559322033898
0.4643850771531667,0.6164383561643836,0.3813559322033898
0.47587203571241193,0.6164383561643836,0.3813559322033898
0.46751810549056694,0.6164383561643836,0.3813559322033898
0.45754766260107904,0.6164383561643836,0.3813559322033898
0.5009526236824793,0.3835616438356164,0.2772277227722772
0.48422151314069145,0.6164383561643836,0.3813559322033898
0.48253262083824366,0.6164383561643836,0.3813559322033898
0.4813198390072339,0.6164383561643836,0.3813559322033898
0.4996123777268684,0.589041095890411,0.3996710526315789
0.48021615857947364,0.6164383561643836,0.3813559322033898
0.4904724955558777,0.6164383561643836,0.3813559322033898
0.4731115502853916,0.6164383561643836,0.3813559322033898
0.5003529164480837,0.3835616438356164,0.2772277227722772
0.45868843508093327,0.6164383561643836,0.3813559322033898
0.4718929545520103,0.6164383561643836,0.3813559322033898
0.4928996293512109,0.6164383561643836,0.3813559322033898
0.498598622949156,0.6164383561643836,0.3813559322033898
0.49886567543630733,0.6164383561643836,0.3813559322033898
0.44251549733828194,0.6164383561643836,0.3813559322033898
0.43733179569244385,0.6164383561643836,0.3813559322033898
0.47473908409680404,0.6164383561643836,0.3813559322033898
0.4552919660529045,0.6164383561643836,0.3813559322033898
0.49674740270392537,0.6164383561643836,0.3813559322033898
0.47812952039992973,0.6164383561643836,0.3813559322033898
0.4499086929510718,0.6164383561643836,0.3813559322033898
0.5065145263933155,0.3767123287671233,0.33870887462047683
0.4577268802956359,0.6164383561643836,0.3813559322033898
0.4586170332072532,0.6164383561643836,0.3813559322033898
0.45058821529558263,0.6164383561643836,0.3813559322033898
0.4739768313218469,0.6164383561643836,0.3813559322033898
0.49106264440980674,0.6164383561643836,0.3813559322033898
0.49378430190151684,0.6164383561643836,0.3813559322033898
0.42908558126998275,0.6164383561643836,0.3813559322033898
0.45610846966913304,0.6164383561643836,0.3813559322033898
0.4725141496324605,0.5976466455918511,0.37539212820295514
0.5065145263933155,0.6164383561643836,0.3996710526315789
0.0211080771703091,0.06343465292991453,0.024307499269161165

            #layer 1
            model.add(Conv2D(number_filter[0], (1, 1), activation='relu', input_shape=(number_of_stocks,seq_len, number_feature),
                             data_format='channels_last', padding="same"))
            print("Conv2D  shape 1" + str(model.output_shape))

            # # Added layer 2
            # model.add(Conv2D(number_filter[1], (1, 21), activation='relu'))
            # print("Conv2D Added shape 1b" + str(model.output_shape))
            # model.add(MaxPool2D(pool_size=(1, 4)))
            # print("MaxPool2D Added shape 1c" + str(model.output_shape))

            #layer 2
            model.add(Conv2D(16, (number_of_stocks, 3), activation='relu'))
            print("Conv2D shape 2" + str(model.output_shape))
            # model.add(MaxPool2D(pool_size=(1, 2)))
            # print("MaxPool2D shape 3" + str(model.output_shape))

            #layer 3
            model.add(Conv2D(number_filter[2], (1, 3), activation='relu', padding="same"))
            print("Conv2D shape 4" + str(model.output_shape))
            # model.add(MaxPool2D(pool_size=(1, 2)))
            # print("MaxPool2D shape 5" + str(model.output_shape))


            model.add(GlobalAveragePooling2D())
            print("GlobalAveragePooling2D shape 5" + str(model.output_shape))

            # model.add(Flatten())
            # print("Flatten shape 6" + str(model.output_shape))
            # model.add(Dropout(drop))
            # print("Dropout shape 7" + str(model.output_shape))
            model.add(Dense(1, activation='sigmoid'))
            print("Dense shape 8" + str(model.output_shape))
